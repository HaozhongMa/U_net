{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1e4b2c6519f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "创建dataser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bd30a201ba6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\model\\CT_data\\train\\imgs\\*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmasks_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\model\\CT_data\\train\\masks\\*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "images_train = glob.glob(r'D:\\model\\CT_data\\train\\imgs\\*.png')\n",
    "masks_train = glob.glob(r'D:\\model\\CT_data\\train\\masks\\*.png')\n",
    "train_count = len(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-06c20eb3c4d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "index = np.random.permutation(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6a1769f9d07d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmasks_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "images_train = np.array(images_train)[index]\n",
    "masks_train = np.array(masks_train)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = glob.glob(r'D:\\model\\CT_data\\valid\\imgs\\*.png')\n",
    "masks_test = glob.glob(r'D:\\model\\CT_data\\valid\\masks\\*.png')\n",
    "test_count = len(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((images_train,masks_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((images_test,masks_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_png(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_masks_png(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img,channels=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = read_images_png(images_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = read_masks_png(masks_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img,mask):\n",
    "    concat_img = tf.concat([img,mask],axis = -1)\n",
    "    concat_img = tf.image.resize(concat_img,(280,280),\n",
    "                                method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    crop_img = tf.image.random_crop(concat_img,[256,256,4])\n",
    "    return crop_img[ :, :, :3], crop_img[ :, :, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1,mask_1 = crop_img(img_1,mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_1.numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask_1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(img,mask):\n",
    "    img = tf.cast(img, tf.float32)/127.5 - 1\n",
    "    mask = tf.cast(mask/255, tf.int32)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "加载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_image(img_path,mask_path):\n",
    "    img = read_images_png(img_path)\n",
    "    mask = read_masks_png(mask_path)\n",
    "    img,mask = crop_img(img,mask)\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    img_f32,mask_int32 = normal(img,mask)\n",
    "    return img_f32,mask_int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_image(img_path,mask_path):\n",
    "    img = read_images_png(img_path)\n",
    "    mask = read_masks_png(mask_path)\n",
    "    img = tf.image.resize(img,(256,256))\n",
    "    mask = tf.image.resize(mask,(256,256))\n",
    "    img_f32,mask_int32 = normal(img,mask)\n",
    "    return img_f32,mask_int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5 \n",
    "BUFFER_SIZE = 10 \n",
    "step_per_epoch = train_count//BATCH_SIZE\n",
    "test_step = test_count//BATCH_SIZE\n",
    "auto = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.map(load_train_image,num_parallel_calls = auto)\n",
    "dataset_test = dataset_test.map(load_test_image,num_parallel_calls = auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in dataset_train.take(1):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow((i.numpy()+1)/2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.squeeze(m.numpy()))\n",
    "    plt.imshow(m.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(auto)\n",
    "dataset_test = dataset_test.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u-net模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down_sample(tf.keras.layers.Layer):\n",
    "    def __int__(self,units):\n",
    "        super(Down_sample,self).__int__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(units,kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(units,kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.pool = tf.keras.layers.MaxPooling2D(pool_size=(2,2))\n",
    "    def call(self,x,is_pool=True):\n",
    "        if is_pool:\n",
    "            x= self.pool(x)\n",
    "        x = self.conv1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up_sample(tf.keras.layers.Layer):\n",
    "    def __int__(self,units):\n",
    "        super(Up_sample,self).__int__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(units,kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(units,kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.deconv = tf.keras.layers.Conv2DTranspose(units//2,\n",
    "                                                    kernel_size=2,\n",
    "                                                    strides=2,\n",
    "                                                    padding='same')\n",
    "    def call(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.deconv(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myU_net_model(tf.keras.Model):\n",
    "    def __int__(self):\n",
    "        super(Unet_model,self).__init__()\n",
    "        self.down_sample_I = Down_sample(64)\n",
    "        self.down_sample_II = Down_sample(128)\n",
    "        self.down_sample_III = Down_sample(256)\n",
    "        self.down_sample_IV = Down_sample(512)\n",
    "        self.down_sample_V = Down_sample(1024)\n",
    "        \n",
    "        self.up_sample=tf.keras.layers.Conv2DTranspose(512,\n",
    "                                                kernel_size=2,\n",
    "                                                strides=2,\n",
    "                                                padding='same')\n",
    "        \n",
    "        self.up_sample_I = Up_sample(512)\n",
    "        self.up_sample_II = Up_sample(256)\n",
    "        self.up_sample_III = Up_sample(128)\n",
    "        \n",
    "        self.conv_last = Down_sample(64)\n",
    "        self.last = tf.keras.layers.Conv2D(2,\n",
    "                                           kernel_size=1,\n",
    "                                           padding='same')\n",
    "        \n",
    "    def call(self,x):\n",
    "        x1 = self.down_sample_I(x,is_pool=False)\n",
    "        x2 = self.down_sample_II(x1)\n",
    "        x3 = self.down_sample_III(x2)\n",
    "        x4 = self.down_sample_IV(x3)\n",
    "        x5 = self.down_sample_V(x4)\n",
    "        \n",
    "        x5 = self.up_sample(x5)\n",
    "        \n",
    "        x5 = tf.concat([x4,x5])\n",
    "        x5 = self.up_sample_I(x5)\n",
    "        \n",
    "        x5 = tf.concat([x3,x5])\n",
    "        x5 = self.up_sample_II(x5)\n",
    "        \n",
    "        x5 = tf.concat([x2,x5])\n",
    "        x5 = self.up_sample_III(x5)\n",
    "        \n",
    "        x5 = tf.concat([x1,x5])\n",
    "        \n",
    "        x5 = self.conv_last(x5,is_pool=False)\n",
    "        \n",
    "        x5 = self.last(x5)\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myU_net_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    def __call__(self,y_ture,y_pred,sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred,axis=-1)\n",
    "        return super().__call__(y_ture,y_pred,sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\n",
    "train_iou = MeanIoU(2,name='tain_iou')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\n",
    "test_iou = MeanIoU(2,name='test_iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss(labels,predictions)\n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels,predictions)\n",
    "    train_iou(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images,labels):\n",
    "    predictions= model(images)\n",
    "    t_loss=loss_object(labels,predictions)\n",
    "    test_loss(t_loss)\n",
    "    \n",
    "    test_accuracy(labels,predictions)\n",
    "    test_iou(labels,predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_iou.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    test_iou.reset_states()\n",
    "    \n",
    "    for images,labels in dataset_train:\n",
    "        train_step(images,labels)\n",
    "        \n",
    "    for test_images,test_labels in dataset_val:\n",
    "        train_step(test_images,test_labels)\n",
    "        \n",
    "    template ='EPOCH {:.3f}, Loss:{:.3f}, Accuracy: {:.3f},\\\n",
    "               IOU:{:.3f},Test Loss:{:.3f},\\\n",
    "               Test Acurracy:{:.3f},Test IOU:{:.3f}'\n",
    "    \n",
    "    print (template.format(epoch+1,\n",
    "                           train_loss.result(),\n",
    "                           train_accuracy.result()*100,\n",
    "                           train_iou.result(),\n",
    "                           test_loss.result(),\n",
    "                           test_accuracy.result()*100,\n",
    "                           test_iou.result()\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
