{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% import\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, PyCharm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DownsampleLayer(tf.keras.layers.Layer):\n",
    "    def __int__(self, units):\n",
    "        \"\"\"\n",
    "        units,cov2d的filters参数？ 这个参数的主要含义是什么？\n",
    "        :param units:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(DownsampleLayer, self).__int__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(units,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(units,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.pool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "    def call(self, inputs, is_pool=True):\n",
    "        \"\"\"\n",
    "        layers类的call方法的重新定义？\n",
    "        :param inputs:\n",
    "        :param is_pool:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if is_pool:\n",
    "            inputs = self.pool(inputs)\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        outputs = tf.nn.relu(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class UpsampleLayer(tf.keras.layers.Layer):\n",
    "    def __int__(self, units):\n",
    "        super(UpsampleLayer, self).__int__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(units, kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(units, kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.deconv = tf.keras.layers.Conv2DTranspose(units // 2,\n",
    "                                                      kernel_size=2,\n",
    "                                                      strides=2,\n",
    "                                                      padding='same')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.deconv(x)\n",
    "        outputs = tf.nn.relu(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class UnetModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    定义模型，这个模型的父类是来自keras的Model类\n",
    "    \"\"\"\n",
    "\n",
    "    def __int__(self):\n",
    "        super(UnetModel, self).__init__()\n",
    "        self.down_sample_I = DownsampleLayer(64)\n",
    "        self.down_sample_II = DownsampleLayer(128)\n",
    "        self.down_sample_III = DownsampleLayer(256)\n",
    "        self.down_sample_IV = DownsampleLayer(512)\n",
    "        self.down_sample_V = DownsampleLayer(1024)\n",
    "        self.up_sample = tf.keras.layers.Conv2DTranspose(512,\n",
    "                                                         kernel_size=2,\n",
    "                                                         strides=2,\n",
    "                                                         padding='same')\n",
    "        self.up_sample_I = UpsampleLayer(512)\n",
    "        self.up_sample_II = UpsampleLayer(256)\n",
    "        self.up_sample_III = UpsampleLayer(128)\n",
    "        self.conv_last = UpsampleLayer(64)\n",
    "        self.last = tf.keras.layers.Conv2D(2,\n",
    "                                           kernel_size=1,\n",
    "                                           padding='same')\n",
    "\n",
    "    def call(self,inputs):\n",
    "        #下采样5层\n",
    "        x1 = self.down_sample_I(inputs,is_pool=False)\n",
    "        x2 = self.down_sample_II(x1)\n",
    "        x3 = self.down_sample_III(x2)\n",
    "        x4 = self.down_sample_IV(x3)\n",
    "        x5 = self.down_sample_V(x4)\n",
    "        #上采样5层\n",
    "        x5 = self.up_sample(x5)\n",
    "\n",
    "        x5 = tf.concat([x4,x5])\n",
    "        x5 = self.up_sample_I(x5)\n",
    "\n",
    "        x5 = tf.concat([x3,x5])\n",
    "        x5 = self.up_sample_II(x5)\n",
    "\n",
    "        x5 = tf.concat([x2,x5])\n",
    "        x5 = self.up_sample_III(x5)\n",
    "\n",
    "        x5 = tf.concat([x1,x5])\n",
    "\n",
    "        x5 = self.conv_last(x5,is_pool=False)\n",
    "\n",
    "        x5 = self.last(x5)\n",
    "        return x5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 定义UnetModel类\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_images_png(path):\n",
    "    \"\"\"\n",
    "    读取数据文件\n",
    "    :param path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    return img\n",
    "\n",
    "def read_masks_png(path):\n",
    "    \"\"\"\n",
    "    读取mask文件\n",
    "    :param path:\n",
    "    :return: (rows,cols,1)\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img,channels=1)\n",
    "    return img\n",
    "\n",
    "#数据增强\n",
    "def crop_img(img,mask):\n",
    "    \"\"\"\n",
    "    叠放后裁剪、翻转\n",
    "    :param img:\n",
    "    :param mask:\n",
    "    :return: (256,256,3),(256,256,1)\n",
    "    \"\"\"\n",
    "    concat_img = tf.concat([img,mask],axis = -1)\n",
    "    concat_img = tf.image.resize(concat_img,(280,280),\n",
    "                                method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    cropped_img = tf.image.random_crop(concat_img,[256,256,4])\n",
    "    print(\"shape of cropped_img is %d\"%cropped_img.shape)\n",
    "    return cropped_img[ :, :, :3], cropped_img[ :, :, 3:]\n",
    "\n",
    "def normal(img,mask):\n",
    "    \"\"\"\n",
    "    对数据进行正态化处理，让值成为[-127.5,0,127.5]的分布状态\n",
    "    :param img:\n",
    "    :param mask:\n",
    "    :return: img(rows,cols,layers=3)(float32),mask(rows,cols,layers=1)(int32)\n",
    "    \"\"\"\n",
    "    img = tf.cast(img, tf.float32)/127.5 - 1\n",
    "    mask = tf.cast(mask/255, tf.int32)\n",
    "    return img, mask\n",
    "\n",
    "def load_train_image(img_path,mask_path):\n",
    "    \"\"\"\n",
    "    读取训练数据集，将图像和mask 合并以后，进行处理\n",
    "    :param img_path:\n",
    "    :param mask_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #读取数据\n",
    "    img = read_images_png(img_path)\n",
    "    mask = read_masks_png(mask_path)\n",
    "    #裁剪\n",
    "    img,mask = crop_img(img,mask)\n",
    "    #翻转\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    img_f32,mask_int32 = normal(img,mask)\n",
    "    return img_f32,mask_int32\n",
    "\n",
    "def load_test_image(img_path,mask_path):\n",
    "    \"\"\"\n",
    "    读取测试数据集，这个函数\n",
    "    todo:修改错误的部分，没有经过280,280的压缩，恐怕会有问题\n",
    "    :param img_path:\n",
    "    :param mask_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #读取数据\n",
    "    img = read_images_png(img_path)\n",
    "    mask = read_masks_png(mask_path)\n",
    "    #直接压缩数据到（256,256,3），（256,256,1）\n",
    "    img = tf.image.resize(img,(256,256))\n",
    "    mask = tf.image.resize(mask,(256,256))\n",
    "    img_f32,mask_int32 = normal(img,mask)\n",
    "    return img_f32, mask_int32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 定义数据预处理函数\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "class MeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    def __call__(self,y_ture,y_pred,sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred,axis=-1)\n",
    "        return super().__call__(y_ture,y_pred,sample_weight=sample_weight)\n",
    "\n",
    "#定义训练步骤\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\n",
    "train_iou = MeanIoU(2,name='tain_iou')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\n",
    "test_iou = MeanIoU(2,name='test_iou')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss(labels,predictions)\n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels,predictions)\n",
    "    train_iou(labels,predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images,labels):\n",
    "    predictions= model(images)\n",
    "    t_loss=loss_object(labels,predictions)\n",
    "    test_loss(t_loss)\n",
    "\n",
    "    test_accuracy(labels,predictions)\n",
    "    test_iou(labels,predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%定义训练过程中使用的函数\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(auto)\n",
    "dataset_test = dataset_test.cache().batch(BATCH_SIZE)\n",
    "\n",
    "for i, m in dataset_train.take(1):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow((i.numpy()+1)/2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.squeeze(m.numpy()))\n",
    "    plt.imshow(m.numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#训练数据列表\n",
    "#train数据集位置\n",
    "images_train_filelist = glob.glob(r'CT_data\\train\\imgs\\*.png')\n",
    "masks_train_filelist = glob.glob(r'CT_data\\train\\masks\\*.png')\n",
    "train_count = len(images_train_filelist)\n",
    "#重新排列数据的顺序\n",
    "index = np.random.permutation(train_count)\n",
    "images_train_filelist = np.array(images_train_filelist)[index]\n",
    "masks_train_filelist = np.array(masks_train_filelist)[index]\n",
    "\n",
    "#验证数据列表\n",
    "#test数据集位置\n",
    "images_test_filelist = glob.glob(r'CT_data\\valid\\imgs\\*.png')\n",
    "masks_test_filelist = glob.glob(r'CT_data\\valid\\masks\\*.png')\n",
    "test_count = len(images_test_filelist)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%读取数据列表\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = UnetModel()\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_iou.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    test_iou.reset_states()\n",
    "    \n",
    "    for images,labels in dataset_train:\n",
    "        train_step(images,labels)\n",
    "        \n",
    "    for test_images,test_labels in dataset_test:\n",
    "        train_step(test_images,test_labels)\n",
    "        \n",
    "    template ='EPOCH {:.3f}, Loss:{:.3f}, Accuracy: {:.3f},\\\n",
    "               IOU:{:.3f},Test Loss:{:.3f},\\\n",
    "               Test Acurracy:{:.3f},Test IOU:{:.3f}'\n",
    "    \n",
    "    print (template.format(epoch+1,\n",
    "                           train_loss.result(),\n",
    "                           train_accuracy.result()*100,\n",
    "                           train_iou.result(),\n",
    "                           test_loss.result(),\n",
    "                           test_accuracy.result()*100,\n",
    "                           test_iou.result()\n",
    "                         ))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%训练步骤\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}